{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"dataset_294.h5\")\n",
    "x = f['x'].value\n",
    "y = f['y'].value\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = scale(x)  #feature scaling\n",
    "x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100) #train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(y_true,y_pred):    #function to check results\n",
    "    total_correctly_predicted = len([i for i in range(len(y_true)) if (y_true[i]==y_pred[i]).sum() == 5])\n",
    "    print(\"Fully correct output\")\n",
    "    print(total_correctly_predicted)\n",
    "    print(total_correctly_predicted/400.)\n",
    "    print(\"hamming loss\")\n",
    "    print(hamming_loss(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(SVC(kernel='rbf',gamma=0.0020,C=5., probability=True ),n_jobs=-1)   #multi label classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = x_train[0:100],y_train[0:100]   #small subset(100 examples) of train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=5.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.002, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=-1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Trained on dataset:(100, 294)\n",
      "Fully correct output\n",
      "139\n",
      "0.3475\n",
      "hamming loss\n",
      "0.198\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(\"*\"*100)\n",
    "print(\"Trained on dataset:\"+str(batch_x.shape))\n",
    "get_result(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = range(100,1600,100)  #batch mode active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Found 49 uncertain examples\n",
      "New Dataset shape(149, 294)\n",
      "Fully correct output\n",
      "158\n",
      "0.395\n",
      "hamming loss\n",
      "0.1885\n",
      "****************************************************************************************************\n",
      "Found 54 uncertain examples\n",
      "New Dataset shape(203, 294)\n",
      "Fully correct output\n",
      "164\n",
      "0.41\n",
      "hamming loss\n",
      "0.177\n",
      "****************************************************************************************************\n",
      "Found 38 uncertain examples\n",
      "New Dataset shape(241, 294)\n",
      "Fully correct output\n",
      "162\n",
      "0.405\n",
      "hamming loss\n",
      "0.1695\n",
      "****************************************************************************************************\n",
      "Found 34 uncertain examples\n",
      "New Dataset shape(275, 294)\n",
      "Fully correct output\n",
      "167\n",
      "0.4175\n",
      "hamming loss\n",
      "0.172\n",
      "****************************************************************************************************\n",
      "Found 40 uncertain examples\n",
      "New Dataset shape(315, 294)\n",
      "Fully correct output\n",
      "167\n",
      "0.4175\n",
      "hamming loss\n",
      "0.1675\n",
      "****************************************************************************************************\n",
      "Found 47 uncertain examples\n",
      "New Dataset shape(362, 294)\n",
      "Fully correct output\n",
      "171\n",
      "0.4275\n",
      "hamming loss\n",
      "0.1675\n",
      "****************************************************************************************************\n",
      "Found 35 uncertain examples\n",
      "New Dataset shape(397, 294)\n",
      "Fully correct output\n",
      "178\n",
      "0.445\n",
      "hamming loss\n",
      "0.1615\n",
      "****************************************************************************************************\n",
      "Found 26 uncertain examples\n",
      "New Dataset shape(423, 294)\n",
      "Fully correct output\n",
      "185\n",
      "0.4625\n",
      "hamming loss\n",
      "0.16\n",
      "****************************************************************************************************\n",
      "Found 38 uncertain examples\n",
      "New Dataset shape(461, 294)\n",
      "Fully correct output\n",
      "184\n",
      "0.46\n",
      "hamming loss\n",
      "0.162\n",
      "****************************************************************************************************\n",
      "Found 45 uncertain examples\n",
      "New Dataset shape(506, 294)\n",
      "Fully correct output\n",
      "188\n",
      "0.47\n",
      "hamming loss\n",
      "0.1535\n",
      "****************************************************************************************************\n",
      "Found 30 uncertain examples\n",
      "New Dataset shape(536, 294)\n",
      "Fully correct output\n",
      "184\n",
      "0.46\n",
      "hamming loss\n",
      "0.1595\n",
      "****************************************************************************************************\n",
      "Found 39 uncertain examples\n",
      "New Dataset shape(575, 294)\n",
      "Fully correct output\n",
      "184\n",
      "0.46\n",
      "hamming loss\n",
      "0.156\n",
      "****************************************************************************************************\n",
      "Found 42 uncertain examples\n",
      "New Dataset shape(617, 294)\n",
      "Fully correct output\n",
      "191\n",
      "0.4775\n",
      "hamming loss\n",
      "0.1475\n",
      "****************************************************************************************************\n",
      "Found 36 uncertain examples\n",
      "New Dataset shape(653, 294)\n",
      "Fully correct output\n",
      "188\n",
      "0.47\n",
      "hamming loss\n",
      "0.149\n",
      "****************************************************************************************************\n",
      "Found 33 uncertain examples\n",
      "New Dataset shape(686, 294)\n",
      "Fully correct output\n",
      "188\n",
      "0.47\n",
      "hamming loss\n",
      "0.151\n"
     ]
    }
   ],
   "source": [
    "for i in batch:\n",
    "    next_batch_x = x_train[i:i+100]\n",
    "    next_batch_y = y_train[i:i+100]\n",
    "    scores = np.abs(model.decision_function(next_batch_x))\n",
    "    tmp_y = next_batch_y\n",
    "    index = [i for i,Sum in enumerate(np.sum(scores<0.2,axis=1)) if Sum!=0]\n",
    "    print(\"*\"*100)\n",
    "    print(\"Found \"+str(len(index))+\" uncertain examples\")\n",
    "    batch_x = np.vstack((batch_x,next_batch_x[index]))\n",
    "    batch_y = np.vstack((batch_y,next_batch_y[index]))\n",
    "    print(\"New Dataset shape\"+str(batch_x.shape))\n",
    "    model.fit(batch_x,batch_y)\n",
    "    y_pred = model.predict(x_test)\n",
    "    get_result(y_test,y_pred) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
